{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/kaggle/input/vehicle-dataset-from-cardekho/car data.csv')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df['Seller_Type'].unique())\n","print(df['Transmission'].unique())\n","print(df['Owner'].unique())"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# missing null values\n","df.isnull().sum()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset = df[['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n","       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset['Current_Year'] = 2020"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset['no_year'] = final_dataset['Current_Year'] - final_dataset['Year']"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset.drop( ['Year','Current_Year'],axis=1,inplace=True )"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset = pd.get_dummies(final_dataset,drop_first=True)\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_dataset.corr()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.pairplot(final_dataset)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cormat = final_dataset.corr()\n","top_corr_features = cormat.index\n","plt.figure(figsize = (20,20))\n","# plot heat map\n","g = sns.heatmap(final_dataset[top_corr_features].corr(),annot =True,cmap='coolwarm')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# idependent and dependent features\n","X = final_dataset.iloc[:,1:]\n","y = final_dataset.iloc[:,:1]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# feature importance\n","from sklearn.ensemble import ExtraTreesRegressor\n","model  = ExtraTreesRegressor()\n","model.fit(X,y.values.ravel())"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.feature_importances_)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot graph of feature importance for better visualization\n","feat_importances = pd.Series(model.feature_importances_,index=x.columns)\n","feat_importances.nlargest(5).plot(kind='barh')\n","plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","regressor=RandomForestRegressor()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Randomized Search CV\n","\n","# Number of trees in random forest\n","n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n","# Number of features to consider at every split\n","max_features = ['auto', 'sqrt']\n","# Maximum number of levels in tree\n","max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n","# max_depth.append(None)\n","# Minimum number of samples required to split a node\n","min_samples_split = [2, 5, 10, 15, 100]\n","# Minimum number of samples required at each leaf node\n","min_samples_leaf = [1, 2, 5, 10]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the random grid\n","random_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","               'min_samples_split': min_samples_split,\n","               'min_samples_leaf': min_samples_leaf}\n","\n","print(random_grid)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the random grid to search for best hyperparameters\n","# First create the base model to tune\n","rf = RandomForestRegressor()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Random search of parameters, using 3 fold cross validation, \n","# search across 100 different combinations\n","rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_random.fit(X_train,y_train)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_random.best_params_"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_random.best_score_"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions=rf_random.predict(X_test)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.distplot(y_test.values.ravel()-predictions)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.scatter(y_test,predictions)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","# open a file where you want to data\n","file = open('radom_forest_regression_model.pkl','wb')\n","\n","# dump infortons to that file\n","pickle.dump(rf_random,file)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{},"execution_count":null,"outputs":[]}]}